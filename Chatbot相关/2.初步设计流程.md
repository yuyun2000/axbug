
| 时间步 | 客户行为     | 大模型行为                                                                                                                                                                            |
| --- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1   | 发送问题     | 记录会话上下文，进入多级处理流水线                                                                                                                                                                |
| 2   |          | 并行执行：  <br>1. 查询理解：分析问题类型、实体、意图；初筛模型（小参数无思维链模型）使用函数调用判断是否回复、回复的语种、是否调用知识库、产品型号等，通过函数的方式返回<br>2. 对话管理：结合历史上下文理解完整意图  <br>3. 知识检索：基于混合检索策略获取候选信息  <br>4. 缓存查询（待做）：检查是否存在相似历史问题<br> |
| 3   |          | 1. 基于问题类型选择处理模型和回答策略  <br>2. 基于知识可信度和多样性评分筛选知识  <br>3. 对知识进行聚合、消歧和排序  <br>4. 选择最适合的回答生成方式(直接回答/引导式/拒答)<br><br>                                                                   |
| 4   | 得到答复     |                                                                                                                                                                                  |
| 5   | 可能的反馈    | 收集反馈，赞或踩，踩的原因（虚假信息，没有帮助，有害信息，其他）                                                                                                                                                 |
| 6   | 继续提问或者退出 |                                                                                                                                                                                  |

反馈机制
保存一些对话记录进行持续改进
1、聊天界面的赞和踩，点赞的一般可以直接作为正向示例添加到知识库
2、上述第3步中知识库分数得分过低的情况，可能需要人为补充


## 问题点

### 不能部署多个知识库
 
因为火山的知识库是按照个数收费的，如果给每个机型部署一个知识库损耗太大，所以让llm通过fc自主选择对应知识库这个方法不太显示
解决办法：使用结构化知识库，把每个机型的各类信息进行结构化存储，每个词条都有对应的名称，另外对用户的输入进行关键词提取，这样可以增加召回的相似度

### 增加是否调用RAG以及调用特定知识库时，做不到一个模型处理
比如对于闲聊的问题，需要有一个前置模型进行判断是否调用知识库
如果调用了，需要将召回的结果送入一个新的模型组织语言进行回复，而做不到一个模型顺序执行 闲聊判断-调用知识库-组织语言。

要么像现在这样每句话都调用一次知识库，加后续prompt让模型判断是否回复。
要么有一个前置模型对用户的输入进行处理，再有一个后置模型处理知识库的内容。
也就是下面两条路径：
用户问题 → 路由模型判断 → 调用检索系统 → 回答模型生成回复
用户问题 → 单一模型(判断+检索+回复)
