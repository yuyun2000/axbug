目前发现的问题点：
1、中文没有进行多音字处理，现在词表中虽然有多音字的词组比如：
```
重复#ch ong f u #2 2 4 4 
折腾#zh e t eng #1 1 5 5 
记载#j i z ai #4 4 3 3 
```
但是实际处理的时候但是单字匹配的

2、没有文本正则化，无法读取数字，符号等信息，中英日都需要有

3、英语对于符号的处理有点问题

4、目前怀疑中英文一起推理的时候，分词有点问题，比如我推理“do you like 足球还是篮球”  他明显的会一个单词一个停顿

5、陌生单词的基本处理




# 解决1
中文多音字处理，使用最长匹配原则即可，而且这个逻辑和日语的g2p过程是通用的，因为日语的词表长得和中文差不多，并且多音字更多更长



# 解决2
需要使用wetext，包含了中英日三语的文本正则化，但是有4个依赖，放到后面再继承


# 解决3
暂时先不管

# 解决4
首先我的推测是正确的，当我输入“do you like 足球还是篮球”时，转换结果如下：
![](../file/Pasted%20image%2020250430092845.png)

每个英语单词后面都被加上了停顿，而且即使输入的是纯英文，他也是一个单词一停顿：
![](../file/Pasted%20image%2020250430093010.png)

解决很简单，只需要在中间加一个if用来忽略空格就好了


# 解决5
陌生单词的思路如下：
1、比如m5stack这个陌生单词，按照中文处理多音字的方法，最长匹配法循环匹配

2、具体流程如下，
依次匹配m5stac m5sta ... m5 m 最终m匹配上这个字母
5stack 5stac... 5 最终匹配上5的发音
stack可以直接匹配上
这样下来匹配得到m five stack


